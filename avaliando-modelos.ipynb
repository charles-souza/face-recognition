{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"faces.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>-0.917374</td>\n",
       "      <td>0.942663</td>\n",
       "      <td>-0.257429</td>\n",
       "      <td>1.447002</td>\n",
       "      <td>-0.268871</td>\n",
       "      <td>0.627252</td>\n",
       "      <td>-0.046882</td>\n",
       "      <td>-1.685941</td>\n",
       "      <td>0.525852</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055401</td>\n",
       "      <td>-2.274048</td>\n",
       "      <td>-2.465725</td>\n",
       "      <td>3.886626</td>\n",
       "      <td>0.269167</td>\n",
       "      <td>0.430756</td>\n",
       "      <td>1.914558</td>\n",
       "      <td>0.902910</td>\n",
       "      <td>2.595966</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0.247517</td>\n",
       "      <td>0.990445</td>\n",
       "      <td>-0.223442</td>\n",
       "      <td>-0.373292</td>\n",
       "      <td>0.191925</td>\n",
       "      <td>-0.213439</td>\n",
       "      <td>0.248923</td>\n",
       "      <td>-1.730467</td>\n",
       "      <td>0.392964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463284</td>\n",
       "      <td>-1.416748</td>\n",
       "      <td>-0.058870</td>\n",
       "      <td>3.580489</td>\n",
       "      <td>0.723680</td>\n",
       "      <td>0.488406</td>\n",
       "      <td>2.272655</td>\n",
       "      <td>0.302743</td>\n",
       "      <td>2.920565</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>-0.450970</td>\n",
       "      <td>-1.194208</td>\n",
       "      <td>0.475538</td>\n",
       "      <td>0.236720</td>\n",
       "      <td>-0.041058</td>\n",
       "      <td>-0.191835</td>\n",
       "      <td>-0.218016</td>\n",
       "      <td>0.102758</td>\n",
       "      <td>0.378250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155984</td>\n",
       "      <td>0.853813</td>\n",
       "      <td>-0.187039</td>\n",
       "      <td>-0.234237</td>\n",
       "      <td>-0.218337</td>\n",
       "      <td>0.098499</td>\n",
       "      <td>0.087090</td>\n",
       "      <td>0.134367</td>\n",
       "      <td>0.432738</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>-1.307045</td>\n",
       "      <td>0.576326</td>\n",
       "      <td>0.714174</td>\n",
       "      <td>-2.455469</td>\n",
       "      <td>-0.693765</td>\n",
       "      <td>-0.021244</td>\n",
       "      <td>0.972243</td>\n",
       "      <td>1.856137</td>\n",
       "      <td>1.052781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587567</td>\n",
       "      <td>1.100624</td>\n",
       "      <td>0.493432</td>\n",
       "      <td>-0.216325</td>\n",
       "      <td>-0.353358</td>\n",
       "      <td>-1.215957</td>\n",
       "      <td>0.863190</td>\n",
       "      <td>0.387483</td>\n",
       "      <td>-0.714543</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>-1.376472</td>\n",
       "      <td>0.448559</td>\n",
       "      <td>-0.938152</td>\n",
       "      <td>1.255337</td>\n",
       "      <td>0.124838</td>\n",
       "      <td>-0.105280</td>\n",
       "      <td>0.182059</td>\n",
       "      <td>-0.710798</td>\n",
       "      <td>0.531238</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401774</td>\n",
       "      <td>-2.340869</td>\n",
       "      <td>-1.079947</td>\n",
       "      <td>1.640460</td>\n",
       "      <td>0.208107</td>\n",
       "      <td>-0.252765</td>\n",
       "      <td>2.125772</td>\n",
       "      <td>0.220471</td>\n",
       "      <td>1.678880</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         0         1         2         3         4         5  \\\n",
       "73          73 -0.917374  0.942663 -0.257429  1.447002 -0.268871  0.627252   \n",
       "74          74  0.247517  0.990445 -0.223442 -0.373292  0.191925 -0.213439   \n",
       "75          75 -0.450970 -1.194208  0.475538  0.236720 -0.041058 -0.191835   \n",
       "76          76 -1.307045  0.576326  0.714174 -2.455469 -0.693765 -0.021244   \n",
       "77          77 -1.376472  0.448559 -0.938152  1.255337  0.124838 -0.105280   \n",
       "\n",
       "           6         7         8  ...       119       120       121       122  \\\n",
       "73 -0.046882 -1.685941  0.525852  ...  1.055401 -2.274048 -2.465725  3.886626   \n",
       "74  0.248923 -1.730467  0.392964  ...  0.463284 -1.416748 -0.058870  3.580489   \n",
       "75 -0.218016  0.102758  0.378250  ... -0.155984  0.853813 -0.187039 -0.234237   \n",
       "76  0.972243  1.856137  1.052781  ... -0.587567  1.100624  0.493432 -0.216325   \n",
       "77  0.182059 -0.710798  0.531238  ...  1.401774 -2.340869 -1.079947  1.640460   \n",
       "\n",
       "         123       124       125       126       127   target  \n",
       "73  0.269167  0.430756  1.914558  0.902910  2.595966  charles  \n",
       "74  0.723680  0.488406  2.272655  0.302743  2.920565  charles  \n",
       "75 -0.218337  0.098499  0.087090  0.134367  0.432738  charles  \n",
       "76 -0.353358 -1.215957  0.863190  0.387483 -0.714543  charles  \n",
       "77  0.208107 -0.252765  2.125772  0.220471  1.678880  charles  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['Unnamed: 0', 'target'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 128)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78,)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISTURANDO TUDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = shuffle(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRATAR LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_encoder.fit(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = out_encoder.transform(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"faces_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.585182</td>\n",
       "      <td>0.506860</td>\n",
       "      <td>0.113615</td>\n",
       "      <td>0.847161</td>\n",
       "      <td>0.972314</td>\n",
       "      <td>0.246608</td>\n",
       "      <td>0.489368</td>\n",
       "      <td>-0.229752</td>\n",
       "      <td>-0.121398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615384</td>\n",
       "      <td>-1.800110</td>\n",
       "      <td>-1.781654</td>\n",
       "      <td>2.644914</td>\n",
       "      <td>0.675368</td>\n",
       "      <td>0.134593</td>\n",
       "      <td>0.718869</td>\n",
       "      <td>0.185666</td>\n",
       "      <td>1.066420</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.211507</td>\n",
       "      <td>0.705608</td>\n",
       "      <td>-0.319360</td>\n",
       "      <td>0.746849</td>\n",
       "      <td>0.671610</td>\n",
       "      <td>-0.831424</td>\n",
       "      <td>1.365845</td>\n",
       "      <td>-0.894239</td>\n",
       "      <td>-0.863984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>-1.993798</td>\n",
       "      <td>-1.045183</td>\n",
       "      <td>1.565684</td>\n",
       "      <td>-0.053970</td>\n",
       "      <td>-1.060496</td>\n",
       "      <td>1.673226</td>\n",
       "      <td>-1.152325</td>\n",
       "      <td>0.796766</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.923114</td>\n",
       "      <td>0.402916</td>\n",
       "      <td>0.223180</td>\n",
       "      <td>1.038836</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>0.052488</td>\n",
       "      <td>0.797666</td>\n",
       "      <td>-0.110839</td>\n",
       "      <td>-0.666240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581508</td>\n",
       "      <td>-1.716912</td>\n",
       "      <td>-1.802735</td>\n",
       "      <td>2.382299</td>\n",
       "      <td>0.709166</td>\n",
       "      <td>-0.057983</td>\n",
       "      <td>0.978862</td>\n",
       "      <td>0.287745</td>\n",
       "      <td>1.126276</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.084849</td>\n",
       "      <td>0.931331</td>\n",
       "      <td>-0.226256</td>\n",
       "      <td>0.852367</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>-0.693591</td>\n",
       "      <td>1.460718</td>\n",
       "      <td>-0.654452</td>\n",
       "      <td>-0.841600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863670</td>\n",
       "      <td>-1.888515</td>\n",
       "      <td>-0.986585</td>\n",
       "      <td>1.726360</td>\n",
       "      <td>-0.304588</td>\n",
       "      <td>-1.063153</td>\n",
       "      <td>1.653649</td>\n",
       "      <td>-1.038273</td>\n",
       "      <td>0.849434</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.012188</td>\n",
       "      <td>0.544110</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.641852</td>\n",
       "      <td>0.421861</td>\n",
       "      <td>-0.781310</td>\n",
       "      <td>1.351522</td>\n",
       "      <td>-1.202856</td>\n",
       "      <td>-0.317362</td>\n",
       "      <td>...</td>\n",
       "      <td>1.123052</td>\n",
       "      <td>-1.697319</td>\n",
       "      <td>-1.315170</td>\n",
       "      <td>2.592839</td>\n",
       "      <td>0.336983</td>\n",
       "      <td>-0.573603</td>\n",
       "      <td>1.323194</td>\n",
       "      <td>-1.152797</td>\n",
       "      <td>1.538043</td>\n",
       "      <td>charles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         0         1         2         3         4         5  \\\n",
       "21          21 -0.585182  0.506860  0.113615  0.847161  0.972314  0.246608   \n",
       "22          22  0.211507  0.705608 -0.319360  0.746849  0.671610 -0.831424   \n",
       "23          23 -0.923114  0.402916  0.223180  1.038836  0.823114  0.052488   \n",
       "24          24 -0.084849  0.931331 -0.226256  0.852367  0.235294 -0.693591   \n",
       "25          25 -0.012188  0.544110  0.012265  0.641852  0.421861 -0.781310   \n",
       "\n",
       "           6         7         8  ...       119       120       121       122  \\\n",
       "21  0.489368 -0.229752 -0.121398  ...  0.615384 -1.800110 -1.781654  2.644914   \n",
       "22  1.365845 -0.894239 -0.863984  ...  0.987119 -1.993798 -1.045183  1.565684   \n",
       "23  0.797666 -0.110839 -0.666240  ...  0.581508 -1.716912 -1.802735  2.382299   \n",
       "24  1.460718 -0.654452 -0.841600  ...  0.863670 -1.888515 -0.986585  1.726360   \n",
       "25  1.351522 -1.202856 -0.317362  ...  1.123052 -1.697319 -1.315170  2.592839   \n",
       "\n",
       "         123       124       125       126       127   target  \n",
       "21  0.675368  0.134593  0.718869  0.185666  1.066420  charles  \n",
       "22 -0.053970 -1.060496  1.673226 -1.152325  0.796766  charles  \n",
       "23  0.709166 -0.057983  0.978862  0.287745  1.126276  charles  \n",
       "24 -0.304588 -1.063153  1.653649 -1.038273  0.849434  charles  \n",
       "25  0.336983 -0.573603  1.323194 -1.152797  1.538043  charles  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 128)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valX = np.array(df_val.drop(['Unnamed: 0', 'target'], axis=1))\n",
    "valY = np.array(df_val.target)\n",
    "valX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_encoder.fit(valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "valY = out_encoder.transform(valY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AVALIANDO ALGORITMOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = knn.predict(trainX)\n",
    "yhat_val   = knn.predict(valX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(model_name, valY, yhat_val):\n",
    "    \n",
    "    cm = confusion_matrix(valY, yhat_val)\n",
    "    total = sum(sum(cm))\n",
    "    acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "    \n",
    "    print(\"MODELO : {}\".format(model_name))\n",
    "    print(\"AcurÃ¡cia: {:.4f}\".format(acc))\n",
    "    print(\"Sensitividade: {:.4f}\".format(sensitivity))\n",
    "    print(\"Especificidade: {:.4f}\".format(specificity))\n",
    "    \n",
    "    from mlxtend.plotting import plot_confusion_matrix\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(5, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO : KNN\n",
      "AcurÃ¡cia: 0.8846\n",
      "Sensitividade: 0.8571\n",
      "Especificidade: 0.9167\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_confusion_matrix(\"KNN\", valY, yhat_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = svm.predict(trainX)\n",
    "yhat_val   = svm.predict(valX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO : SVM\n",
      "AcurÃ¡cia: 0.9231\n",
      "Sensitividade: 1.0000\n",
      "Especificidade: 0.8333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_confusion_matrix(\"SVM\", valY, yhat_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USANDO O KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "valY = to_categorical(valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 8,386\n",
      "Trainable params: 8,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\", input_shape=(128,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.8439 - accuracy: 0.5641\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.7949\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.8846\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9359\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.9231\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9744\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9231\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9487\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9487\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9615\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9872\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.0675 - accuracy: 0.9872\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.0776 - accuracy: 0.9744\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9872\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9872\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.9744\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 910us/step - loss: 0.0465 - accuracy: 0.9872\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 969us/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 964us/step - loss: 0.0402 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 932us/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 978us/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 976us/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 940us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 984us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 939us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 966us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.9872\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbf434fcf8>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model.predict(trainX)\n",
    "yhat_val   = model.predict(valX) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_val = np.argmax(yhat_val, axis=1)\n",
    "yhat_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valY = np.argmax(valY, axis=1)\n",
    "valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO : KERAS\n",
      "AcurÃ¡cia: 0.8462\n",
      "Sensitividade: 0.8571\n",
      "Especificidade: 0.8333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_confusion_matrix(\"KERAS\", valY, yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('faces.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
